{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsbombpy import sb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I de første celler er Thors kode fra \"passing seqeunces creation.ipynb\" kopieret.\n",
    "Jeg laver en ny markdown celle, når koden begynder at adskille sig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morten/anaconda3/lib/python3.11/site-packages/statsbombpy/api_client.py:21: NoAuthWarning: credentials were not supplied. open data access only\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#find ids for barca home matches - only home games because then locations can be compared between different games\n",
    "matches = sb.matches(competition_id=11, season_id=90)\n",
    "barca_home_matches = matches[matches[\"home_team\"]==\"Barcelona\"]\n",
    "match_ids = barca_home_matches['match_id'].values.tolist()\n",
    "#All events sorted for barca home games and possession \n",
    "events = sb.competition_events(\n",
    "    country=\"Spain\",\n",
    "    division= \"La Liga\",\n",
    "    season=\"2020/2021\",\n",
    "    gender=\"male\"\n",
    ")\n",
    "events = events[events['match_id'].isin(match_ids)]\n",
    "df = events[events[\"team\"]==\"Barcelona\"]\n",
    "df = df[df[\"possession_team\"]==\"Barcelona\"]\n",
    "#filter threshold for Xg:\n",
    "df_xg = df[~df['shot_statsbomb_xg'].between(0, 0.05)]\n",
    "#Events sorted in a specific order so each passing sequence is correctly sorted\n",
    "sequences_sorted = df_xg.sort_values(['match_id', 'period','timestamp'], ascending=[True, True, True])\n",
    "#make new ids because right now there is ids from 1 to x for each match but it repeats from 1 and up in every match so each possession id points to different matches \n",
    "# - i just put the possession id after match_id in the newly created id\n",
    "sequences_sorted['possession_id'] = sequences_sorted['match_id'].astype(str) + sequences_sorted['possession'].astype(str)\n",
    "sequences_sorted['possession_id'] = sequences_sorted['possession_id'].astype(int)\n",
    "#get the ids of sequences which contain a shot (contain an xg value)\n",
    "shot_sequences = sequences_sorted[sequences_sorted[\"shot_statsbomb_xg\"].notna()]\n",
    "shot_sequences_ids = shot_sequences[\"possession_id\"].unique()\n",
    "#filter for possession sequences which end with a shot\n",
    "sequences_filtered = sequences_sorted[sequences_sorted['possession_id'].isin(shot_sequences_ids)]\n",
    "#fill all rows with an xg for the corresponding sequence - right now there are many missing values in \"shot_statsbomb_xg\"\n",
    "sequences_filtered['xg'] = sequences_filtered.groupby('possession_id')['shot_statsbomb_xg'].transform(lambda group: group.fillna(method='ffill').fillna(method='bfill'))\n",
    "#now we dont need the shot event rows any more so remove them\n",
    "sequences_filtered = sequences_filtered[sequences_filtered[\"type\"]!=\"Shot\"]\n",
    "#filter the df to only include row with an id the of a pass recipient and we subset the columns\n",
    "player_final_sequences =  sequences_filtered[sequences_filtered[\"pass_recipient\"].notna()][[\"player_id\", \"pass_recipient_id\", \"possession_id\", \"xg\",\"timestamp\"]]\n",
    "player_final_sequences\n",
    "player_final_sequences = player_final_sequences.sort_values(['possession_id', 'timestamp'], ascending=[True, True])\n",
    "player_final_sequences = player_final_sequences[player_final_sequences['player_id'] != player_final_sequences['pass_recipient_id']]\n",
    "player_final_sequences['sequence'] = player_final_sequences.groupby('possession_id').cumcount(ascending=False) + 1\n",
    "player_final_sequences\n",
    "#remove sequences with few passes if wanted\n",
    "index_counts = player_final_sequences['possession_id'].value_counts()\n",
    "player_final_sequences = player_final_sequences[player_final_sequences['possession_id'].isin(index_counts[index_counts > 5].index)]\n",
    "possession_index = player_final_sequences[\"possession_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find ids of those possessions that result in a goal\n",
    "goal_posession_index = sequences_filtered.loc[sequences_filtered[\"shot_outcome\"]==\"Goal\", \"possession_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu begynder jeg at arbejde på, at lave spillerne til nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_id</th>\n",
       "      <th>pass_recipient_id</th>\n",
       "      <th>possession_id</th>\n",
       "      <th>xg</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37125</th>\n",
       "      <td>20055.0</td>\n",
       "      <td>5492.0</td>\n",
       "      <td>37644403</td>\n",
       "      <td>0.069672</td>\n",
       "      <td>00:00:23.093</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37126</th>\n",
       "      <td>5492.0</td>\n",
       "      <td>5213.0</td>\n",
       "      <td>37644403</td>\n",
       "      <td>0.069672</td>\n",
       "      <td>00:00:26.568</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37127</th>\n",
       "      <td>5213.0</td>\n",
       "      <td>8118.0</td>\n",
       "      <td>37644403</td>\n",
       "      <td>0.069672</td>\n",
       "      <td>00:00:30.323</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37128</th>\n",
       "      <td>8118.0</td>\n",
       "      <td>5492.0</td>\n",
       "      <td>37644403</td>\n",
       "      <td>0.069672</td>\n",
       "      <td>00:00:34.279</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37129</th>\n",
       "      <td>5492.0</td>\n",
       "      <td>5213.0</td>\n",
       "      <td>37644403</td>\n",
       "      <td>0.069672</td>\n",
       "      <td>00:00:39.131</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14306</th>\n",
       "      <td>5203.0</td>\n",
       "      <td>6379.0</td>\n",
       "      <td>3773672171</td>\n",
       "      <td>0.101797</td>\n",
       "      <td>00:47:00.677</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14307</th>\n",
       "      <td>6379.0</td>\n",
       "      <td>22390.0</td>\n",
       "      <td>3773672171</td>\n",
       "      <td>0.101797</td>\n",
       "      <td>00:47:04.417</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14308</th>\n",
       "      <td>22390.0</td>\n",
       "      <td>21881.0</td>\n",
       "      <td>3773672171</td>\n",
       "      <td>0.101797</td>\n",
       "      <td>00:47:05.103</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14309</th>\n",
       "      <td>21881.0</td>\n",
       "      <td>6947.0</td>\n",
       "      <td>3773672171</td>\n",
       "      <td>0.101797</td>\n",
       "      <td>00:47:07.817</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14310</th>\n",
       "      <td>6947.0</td>\n",
       "      <td>21881.0</td>\n",
       "      <td>3773672171</td>\n",
       "      <td>0.101797</td>\n",
       "      <td>00:47:08.624</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1607 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       player_id  pass_recipient_id  possession_id        xg     timestamp  \\\n",
       "37125    20055.0             5492.0       37644403  0.069672  00:00:23.093   \n",
       "37126     5492.0             5213.0       37644403  0.069672  00:00:26.568   \n",
       "37127     5213.0             8118.0       37644403  0.069672  00:00:30.323   \n",
       "37128     8118.0             5492.0       37644403  0.069672  00:00:34.279   \n",
       "37129     5492.0             5213.0       37644403  0.069672  00:00:39.131   \n",
       "...          ...                ...            ...       ...           ...   \n",
       "14306     5203.0             6379.0     3773672171  0.101797  00:47:00.677   \n",
       "14307     6379.0            22390.0     3773672171  0.101797  00:47:04.417   \n",
       "14308    22390.0            21881.0     3773672171  0.101797  00:47:05.103   \n",
       "14309    21881.0             6947.0     3773672171  0.101797  00:47:07.817   \n",
       "14310     6947.0            21881.0     3773672171  0.101797  00:47:08.624   \n",
       "\n",
       "       sequence  \n",
       "37125        12  \n",
       "37126        11  \n",
       "37127        10  \n",
       "37128         9  \n",
       "37129         8  \n",
       "...         ...  \n",
       "14306         5  \n",
       "14307         4  \n",
       "14308         3  \n",
       "14309         2  \n",
       "14310         1  \n",
       "\n",
       "[1607 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_final_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "#iterate over possession ids and each row and append edges to a list for each graph and append that graph to a graphs dictionary (directed graph created with \"nx.DiGraph(edges)\")\n",
    "#xg added as an attribute for each graph\n",
    "graphs_dict = {}\n",
    "for j in possession_index:\n",
    "    edges = []\n",
    "    for i in player_final_sequences.index:\n",
    "        if j == player_final_sequences[\"possession_id\"][i]:\n",
    "            edges.append((player_final_sequences[\"player_id\"][i], player_final_sequences[\"pass_recipient_id\"][i]))\n",
    "            if j not in graphs_dict:\n",
    "                graphs_dict[j] = {\"xg\": player_final_sequences[\"xg\"][i], \"graph\": None}\n",
    "            else:\n",
    "                graphs_dict[j][\"xg\"] = player_final_sequences[\"xg\"][i]\n",
    "                \n",
    "    graph = nx.DiGraph()\n",
    "    graph.add_edges_from(edges)\n",
    "\n",
    "    # Add sequence as an edge attribute\n",
    "    for i in player_final_sequences.index:\n",
    "        if j == player_final_sequences[\"possession_id\"][i]:\n",
    "            graph[player_final_sequences[\"player_id\"][i]][player_final_sequences[\"pass_recipient_id\"][i]]['sequence'] = player_final_sequences[\"sequence\"][i]\n",
    "\n",
    "    graphs_dict[j][\"graph\"] = graph\n",
    "\n",
    "    graph_list = [value[\"graph\"] for value in graphs_dict.values()]\n",
    "\n",
    "graph_list = [value[\"graph\"] for value in graphs_dict.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "man kunne gøre noget med at fixere spillerene på deres positioner på banen for at visualisere det. Det gider jeg ikke at bruge tid på lige nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_list = [value[\"graph\"] for value in graphs_dict.values()]\n",
    "edge_matrix = [list(graph.edges(data=True)) for graph in graph_list]\n",
    "GRAPH_DB = graph_list  # List of graphs in the database\n",
    "min_sup = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 2:\n",
      "Frequent subgraphs of size 2:\n",
      "Edge 5203.0 -> 5503.0, Attributes: {'sequence': 4}\n",
      "Edge 6826.0 -> 5211.0, Attributes: {'sequence': 2}\n",
      "Edge 5211.0 -> 5503.0, Attributes: {'sequence': 10}\n",
      "Edge 6826.0 -> 5211.0, Attributes: {'sequence': 2}\n",
      "Edge 5211.0 -> 5503.0, Attributes: {'sequence': 10}\n",
      "Edge 5203.0 -> 5503.0, Attributes: {'sequence': 4}\n",
      "\n",
      "Iteration 3:\n",
      "Frequent subgraphs of size 3:\n",
      "Edge 5203.0 -> 5503.0, Attributes: {'sequence': 4}\n",
      "Edge 6826.0 -> 5211.0, Attributes: {'sequence': 2}\n",
      "Edge 5211.0 -> 5503.0, Attributes: {'sequence': 10}\n",
      "Edge 5211.0 -> 5503.0, Attributes: {'sequence': 10}\n",
      "Edge 6826.0 -> 5211.0, Attributes: {'sequence': 2}\n",
      "Edge 5203.0 -> 5503.0, Attributes: {'sequence': 4}\n",
      "\n",
      "Iteration 4:\n",
      "No frequent subgraphs found for size 4. Terminating.\n",
      "[(5211.0, 5503.0)]\n",
      "[(5203.0, 5503.0)]\n",
      "[(6826.0, 5211.0)]\n",
      "[(5203.0, 5503.0), (6826.0, 5211.0)]\n",
      "[(5211.0, 5503.0), (6826.0, 5211.0)]\n",
      "[(5211.0, 5503.0), (5203.0, 5503.0)]\n",
      "[(5203.0, 5503.0), (6826.0, 5211.0), (5211.0, 5503.0)]\n",
      "[(5211.0, 5503.0), (6826.0, 5211.0), (5203.0, 5503.0)]\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from networkx.algorithms.isomorphism import DiGraphMatcher\n",
    "\n",
    "\n",
    "def frequent_singletons(min_sup, edge_matrix):\n",
    "    items_counted = {}\n",
    "    edge_attributes = {}\n",
    "\n",
    "    for edge_list in edge_matrix:\n",
    "        for edge in edge_list:\n",
    "            # Use only source and target nodes for counting\n",
    "            edge_key = (edge[0], edge[1])\n",
    "            items_counted[edge_key] = items_counted.get(edge_key, 0) + 1\n",
    "            \n",
    "            # Store the edge attributes\n",
    "            if edge_key not in edge_attributes:\n",
    "                edge_attributes[edge_key] = edge[2]\n",
    "\n",
    "    # Filter edges that meet the min_sup\n",
    "    F = [key for key, value in items_counted.items() if value >= min_sup]\n",
    "    \n",
    "    F_graphs = []\n",
    "    for edge in F:\n",
    "        g = nx.DiGraph()\n",
    "        g.add_edge(edge[0], edge[1], **edge_attributes[edge])  # Add edge with original attributes\n",
    "        F_graphs.append(g)\n",
    "    \n",
    "    return F_graphs\n",
    "\n",
    "def generate_candidates(F, k):\n",
    "    candidates = set()\n",
    "    \n",
    "    # Iterate over all pairs of frequent subgraphs (F)\n",
    "    for g1, g2 in combinations(F, 2):\n",
    "\n",
    "        edges_g1 = sorted(g1.edges(data=True), key=lambda e: e[2].get('sequence', 0))\n",
    "        edges_g2 = sorted(g2.edges(data=True), key=lambda e: e[2].get('sequence', 0))\n",
    "        edges_g1 = edges_g1[0]\n",
    "        edges_g2 = edges_g2[0]\n",
    "        \n",
    "        if edges_g1[2].get('sequence') > edges_g2[2].get('sequence') or edges_g1[2].get('sequence') < edges_g2[2].get('sequence'):\n",
    "            union_graph = nx.compose(g1, g2)\n",
    "            \n",
    "            # Ensure that the union has the correct number of edges\n",
    "            if union_graph.number_of_edges() == k:  # Check edge size instead of node size\n",
    "                candidates.add(union_graph)\n",
    "    \n",
    "    return candidates\n",
    "\n",
    "# Count the support for each candidate in the graph database\n",
    "def count_support(C, graph_db):\n",
    "    F_count = {}\n",
    "    for graph in graph_db:\n",
    "        for candidate in C:\n",
    "            GM = DiGraphMatcher(graph, candidate)\n",
    "            if GM.subgraph_is_isomorphic():  # Check for subgraph isomorphism\n",
    "                F_count[candidate] = F_count.get(candidate, 0) + 1\n",
    "    return F_count\n",
    "\n",
    "# Filter frequent candidates based on minimum support\n",
    "def filter_frequent(F_count, min_sup):\n",
    "    return [key for key, value in F_count.items() if value >= min_sup]\n",
    "\n",
    "# Main function to run the apriori graph mining algorithm\n",
    "def apriori_graph_mining(min_sup, edge_matrix, graph_db, max_k):\n",
    "    frequent_total = []\n",
    "    \n",
    "    # Step 1: Find frequent singletons (edges)\n",
    "    F = frequent_singletons(min_sup, edge_matrix)\n",
    "    \n",
    "    # Add initial frequent items to the total list\n",
    "    frequent_total.extend(F)\n",
    "    \n",
    "    k = 2  # Start with size-2 subgraphs\n",
    "    while k <= max_k:\n",
    "        print(f\"\\nIteration {k}:\")\n",
    "        \n",
    "        # Step 2: Generate candidate subgraphs of size k\n",
    "        C = generate_candidates(F, k)\n",
    "        \n",
    "        # Step 3: Count support for each candidate in the graph database\n",
    "        F_count = count_support(C, graph_db)\n",
    "        \n",
    "        # Step 4: Filter out frequent candidates that meet the minimum support\n",
    "        F = filter_frequent(F_count, min_sup)\n",
    "        \n",
    "        if not F:  # If no frequent candidates are found, stop the algorithm\n",
    "            print(f\"No frequent subgraphs found for size {k}. Terminating.\")\n",
    "            break\n",
    "        \n",
    "        # Add frequent items to the total list\n",
    "        frequent_total.extend(F)\n",
    "        \n",
    "        print(f\"Frequent subgraphs of size {k}:\")\n",
    "        for subgraph in F:\n",
    "            for u, v, attr in subgraph.edges(data=True):\n",
    "                print(f\"Edge {u} -> {v}, Attributes: {attr}\")\n",
    "        \n",
    "        k += 1  # Move to the next size of subgraphs\n",
    "\n",
    "    return frequent_total\n",
    "\n",
    "\n",
    "graph_list = [value[\"graph\"] for value in graphs_dict.values()]\n",
    "\n",
    "edge_matrix = [list(graph.edges(data=True)) for graph in graph_list]\n",
    "GRAPH_DB = graph_list  # List of graphs in the database\n",
    "min_sup = 0\n",
    "\n",
    "\n",
    "frequents = apriori_graph_mining(20, edge_matrix, GRAPH_DB, 5)\n",
    "for pattern in frequents:\n",
    "    print(pattern.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x300d48850>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "game_pos = 377366114\n",
    "\n",
    "# Draw the graph using the positions\n",
    "nx.draw_networkx(graphs_dict[game_pos][\"graph\"])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graphs_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
