{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional\n",
    "import torch_geometric.nn \n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import random\n",
    "from torch_geometric.nn import GATv2Conv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_graphs = pd.read_pickle('/Users/MathildeStouby/Desktop/P5 GitHub/5-semester/Momentum graphs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_nodes = []\n",
    "for graph in pkl_graphs.values():\n",
    "    temp = [node for node in graph.nodes() if node not in unique_nodes]\n",
    "    unique_nodes.extend(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_pos = dict(enumerate(unique_nodes))\n",
    "pos_to_idx = {pos : idx for idx, pos in idx_to_pos.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[23, 26], edge_index=[2, 92], weight=[92])\n"
     ]
    }
   ],
   "source": [
    "pyg_data = []\n",
    "\n",
    "#add node attributes\n",
    "for graph in pkl_graphs.values():\n",
    "    filtered_edges = [(u, v) for u, v, d in graph.edges(data=True) if d['weight'] > 3]\n",
    "    filtered_graph = graph.edge_subgraph(filtered_edges)\n",
    "\n",
    "    closeness = nx.closeness_centrality(filtered_graph)\n",
    "    betweenness = nx.closeness_centrality(filtered_graph)\n",
    "    pagerank = nx.pagerank(graph, weight='weight')\n",
    "    centrality_list = [closeness, betweenness, pagerank] \n",
    "\n",
    "    adj_dict = nx.to_dict_of_dicts(graph)\n",
    "    \n",
    "    for node in list(graph.nodes()):\n",
    "        adj_vect = np.zeros((len(unique_nodes)))\n",
    "        players = adj_dict[node]\n",
    "        for key, value in players.items():\n",
    "            adj_vect[pos_to_idx[key]] = value['weight']\n",
    "        adj_vect = torch.from_numpy(adj_vect).float()\n",
    "        centrality_vect = []\n",
    "        for measure in centrality_list:\n",
    "            if node in list(measure.keys()):\n",
    "                centrality_vect.append(measure[node])\n",
    "            else:\n",
    "                centrality_vect.append(0)\n",
    "        centrality_vect = torch.Tensor(centrality_vect).float()        \n",
    "        graph.nodes[node]['x'] = torch.cat((adj_vect, centrality_vect), -1)\n",
    "\n",
    "    for node in unique_nodes:\n",
    "        if node not in graph.nodes:\n",
    "            graph.add_node(node) \n",
    "            graph.nodes[node]['x'] = torch.from_numpy(np.zeros((len(unique_nodes)+3))).float()  \n",
    "            \n",
    "\n",
    "    data = from_networkx(graph)\n",
    "    try:\n",
    "        data.momentum\n",
    "        pyg_data.append(data)\n",
    "    except:\n",
    "        print(data)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = random.sample(range(len(pyg_data)), int(len(pyg_data) * 0.8))\n",
    "test_idx = [i for i in range(len(pyg_data)) if i not in train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_heads, v2 = True):\n",
    "        super(GAT, self).__init__()\n",
    "        self.layer1= GATv2Conv(input_dim, hidden_dim, heads=num_heads)\n",
    "        self.layer2= GATv2Conv(hidden_dim * num_heads, hidden_dim, heads=num_heads)\n",
    "        self.layer3 = GATv2Conv(hidden_dim * num_heads, output_dim, heads=1, concat=False)\n",
    "        self.activation_function = nn.Tanh()\n",
    "     \n",
    "\n",
    "    def forward(self, input, edge_index):\n",
    "        output = self.activation_function(self.layer1(input, edge_index))\n",
    "        output = self.activation_function(self.layer2(output, edge_index))\n",
    "        output = self.layer3(output, edge_index)\n",
    "        output = output.mean(dim=0) \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(unique_nodes)+3\n",
    "lr = 0.01\n",
    "\n",
    "gat = GAT(input_dim = input_dim, hidden_dim = 5, output_dim = 1, num_heads = 8)\n",
    "optimizer = torch.optim.SGD(gat.parameters(), lr=lr)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "epochs_num = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]/Users/MathildeStouby/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 434/434 [00:02<00:00, 178.33it/s]\n",
      "  5%|▌         | 1/20 [00:02<00:46,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [00:02<00:00, 161.05it/s]\n",
      " 10%|█         | 2/20 [00:05<00:46,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [00:02<00:00, 155.49it/s]\n",
      " 15%|█▌        | 3/20 [00:07<00:45,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [00:02<00:00, 200.84it/s]\n",
      " 20%|██        | 4/20 [00:10<00:39,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.0068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [00:02<00:00, 185.60it/s]\n",
      " 25%|██▌       | 5/20 [00:12<00:36,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [00:02<00:00, 160.41it/s]\n",
      " 30%|███       | 6/20 [00:15<00:35,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [00:02<00:00, 199.34it/s]\n",
      " 35%|███▌      | 7/20 [00:17<00:31,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [00:02<00:00, 205.48it/s]\n",
      " 40%|████      | 8/20 [00:19<00:27,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.0064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [00:02<00:00, 201.52it/s]\n",
      " 45%|████▌     | 9/20 [00:21<00:24,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [00:02<00:00, 195.49it/s]\n",
      " 50%|█████     | 10/20 [00:23<00:22,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [00:02<00:00, 180.17it/s]\n",
      " 55%|█████▌    | 11/20 [00:26<00:20,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [00:02<00:00, 207.13it/s]\n",
      " 60%|██████    | 12/20 [00:28<00:17,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [00:02<00:00, 193.89it/s]\n",
      " 65%|██████▌   | 13/20 [00:30<00:15,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [00:02<00:00, 201.23it/s]\n",
      " 70%|███████   | 14/20 [00:32<00:13,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [00:02<00:00, 197.38it/s]\n",
      " 75%|███████▌  | 15/20 [00:34<00:11,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [00:02<00:00, 191.97it/s]\n",
      " 80%|████████  | 16/20 [00:37<00:08,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [00:02<00:00, 210.33it/s]\n",
      " 85%|████████▌ | 17/20 [00:39<00:06,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [00:02<00:00, 198.34it/s]\n",
      " 90%|█████████ | 18/20 [00:41<00:04,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [00:02<00:00, 180.64it/s]\n",
      " 95%|█████████▌| 19/20 [00:43<00:02,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [00:02<00:00, 188.47it/s]\n",
      "100%|██████████| 20/20 [00:46<00:00,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GAT(\n",
       "  (layer1): GATv2Conv(26, 5, heads=8)\n",
       "  (layer2): GATv2Conv(40, 5, heads=8)\n",
       "  (layer3): GATv2Conv(40, 1, heads=1)\n",
       "  (activation_function): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for epoch in tqdm.tqdm(range(epochs_num)):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for idx in tqdm.tqdm(range(len(train_idx))):\n",
    "        \n",
    "        input = pyg_data[idx].x\n",
    "        edge_idx = pyg_data[idx].edge_index\n",
    "        label = pyg_data[idx]['momentum']\n",
    "    \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = gat(input, edge_idx)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        # optimizer.step()\n",
    "        for p in gat.parameters():\n",
    "            p.data.add_(p.grad.data, alpha=-lr)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss/len(train_idx):.4f}\") \n",
    "gat.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred  = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx in test_idx:\n",
    "        output = gat(pyg_data[idx].x, pyg_data[idx].edge_index)\n",
    "        y_pred.append(output)\n",
    "        y_true.append(pyg_data[idx].momentum)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05980244"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
